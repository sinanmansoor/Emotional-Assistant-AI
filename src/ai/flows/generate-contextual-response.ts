// This is an autogenerated file from Firebase Studio.

'use server';

/**
 * @fileOverview This file defines a Genkit flow for generating contextual responses based on user emotion and input text.
 *
 * - generateContextualResponse - A function that takes user input and emotion data to generate an appropriate response.
 * - GenerateContextualResponseInput - The input type for the generateContextualResponse function.
 * - GenerateContextualResponseOutput - The return type for the generateContextualResponse function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';
import wav from 'wav';

const GenerateContextualResponseInputSchema = z.object({
  text: z.string().describe('The text input from the user.'),
  emotion: z.string().describe('The detected emotion of the user.'),
  conversationHistory: z.string().optional().describe('The past conversation history.'),
});
export type GenerateContextualResponseInput = z.infer<typeof GenerateContextualResponseInputSchema>;

const GenerateContextualResponseOutputSchema = z.object({
  response: z.string().describe('The AI generated response.'),
  audio: z.string().describe('The AI generated audio response in base64 encoded WAV format.'),
});
export type GenerateContextualResponseOutput = z.infer<typeof GenerateContextualResponseOutputSchema>;

export async function generateContextualResponse(input: GenerateContextualResponseInput): Promise<GenerateContextualResponseOutput> {
  return generateContextualResponseFlow(input);
}

const prompt = ai.definePrompt({
  name: 'generateContextualResponsePrompt',
  input: {schema: GenerateContextualResponseInputSchema},
  output: {schema: z.object({ response: z.string() })},
  prompt: `You are an empathetic AI assistant named EmotiMate, designed to provide support and engage in natural conversation.

You will take user input and emotion data to generate an appropriate response. You will also take the conversation history into account.

Emotion: {{{emotion}}}
Input: {{{text}}}
Conversation History: {{{conversationHistory}}}

Response: `,
  config: {
    safetySettings: [
      {
        category: 'HARM_CATEGORY_HATE_SPEECH',
        threshold: 'BLOCK_ONLY_HIGH',
      },
      {
        category: 'HARM_CATEGORY_DANGEROUS_CONTENT',
        threshold: 'BLOCK_NONE',
      },
      {
        category: 'HARM_CATEGORY_HARASSMENT',
        threshold: 'BLOCK_MEDIUM_AND_ABOVE',
      },
      {
        category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT',
        threshold: 'BLOCK_LOW_AND_ABOVE',
      },
    ],
  },
});

const generateContextualResponseFlow = ai.defineFlow(
  {
    name: 'generateContextualResponseFlow',
    inputSchema: GenerateContextualResponseInputSchema,
    outputSchema: GenerateContextualResponseOutputSchema,
  },
  async input => {
    const {output: rawResponse} = await prompt(input);
    const response = rawResponse?.response ?? '';

    let audio = '';
    if (response) {
        const { media } = await ai.generate({
          model: 'googleai/gemini-2.5-flash-preview-tts',
          config: {
            responseModalities: ['AUDIO'],
            speechConfig: {
              voiceConfig: {
                prebuiltVoiceConfig: { voiceName: 'Algenib' },
              },
            },
          },
          prompt: response,
        });
        if (!media) {
          throw new Error('no media returned');
        }
        const audioBuffer = Buffer.from(
          media.url.substring(media.url.indexOf(',') + 1),
          'base64'
        );
        audio = 'data:audio/wav;base64,' + (await toWav(audioBuffer));
    }


    return { response, audio };
  }
);

async function toWav(
  pcmData: Buffer,
  channels = 1,
  rate = 24000,
  sampleWidth = 2
): Promise<string> {
  return new Promise((resolve, reject) => {
    const writer = new wav.Writer({
      channels,
      sampleRate: rate,
      bitDepth: sampleWidth * 8,
    });

    let bufs = [] as any[];
    writer.on('error', reject);
    writer.on('data', function (d) {
      bufs.push(d);
    });
    writer.on('end', function () {
      resolve(Buffer.concat(bufs).toString('base64'));
    });

    writer.write(pcmData);
    writer.end();
  });
}
